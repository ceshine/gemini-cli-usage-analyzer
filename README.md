# Gemini-CLI-Usage-Analyzer

This project provides a simple command-line tool that helps you analyze token usage in your Gemini CLI sessions. It relies on the OpenTelemetry observability support provided by Gemini CLI and implements a pruning and simplification routine, enabled by default, to reduce the size of the OpenTelemetry log files and prevent them from consuming excessive disk space.

Motivation: I wanted to evaluate my token usage in the Gemini CLI to determine whether the paid subscription was worth it for me. I looked for a Gemini CLI equivalent of the [ccusage](https://github.com/ryoppippi/ccusage) tool for Claude Code, but I couldn't find one. Although I could use GCP or other tools that support OpenTelemetry to collect and analyze the OpenTelemetry logs generated by the Gemini CLI, they are too heavyweight (they require additional tooling or learning to use a complicated dashboard) for my simple use case. Therefore, I decided to build one myself.

Caveats: Although this project is highly inspired by [ccusage](https://github.com/ryoppippi/ccusage), it requires a bit more configuration due to the extra OpenTelemetry layer. The entire pipeline is also more brittle because of the post-processing of OpenTelemetry logs. **Additionally, an active internet connection is required to fetch the latest model pricing information.** The workflow recommended in the usage section below should work perfectly if you just want the token usage data. However, if you want to use the OpenTelemetry logs for deeper analysis that requires the full information, including the prompts and model responses, you'll need to enable the appropriate flags when running this tool and manage the raw OpenTelemetry log files yourself.

Disclosure: This project was developed with substantial assistance from the Gemini CLI, which is powered by the Gemini 3 Pro (Preview), the Gemini 2.5 Flash, and the Gemini 2.5 Flash Lite models.

## Prerequisite: Enable OpenTelemetry Support in Gemini CLI

To use this tool, you must enable [local file-based OpenTelemetry support](https://geminicli.com/docs/cli/telemetry/#file-based-output-recommended) in the Gemini CLI.

Add the following `telemetry` configuration to your global settings file (usually at `~/.gemini/settings.json`) or your project-specific `.gemini/settings.json`:

```json
{
  "telemetry": {
    "enabled": true,
    "target": "local",
    "otlpEndpoint": "",
    "outfile": ".gemini/telemetry.log"
  }
}
```

**Note:** Changes to the `telemetry` configuration in `settings.json` often require restarting your Gemini CLI session for them to take effect.

**Configuration Note:**

The `outfile` setting above (`".gemini/telemetry.log"`) tells the Gemini CLI to save telemetry logs inside the `.gemini` folder of the **current working directory** where the CLI is launched. This is the recommended setup, as it keeps logs specific to each project.

Alternatively, you can set `outfile` to an absolute path (e.g., `"~/.gemini/telemetry.log"`) to aggregate logs from all projects into a single file. However, be aware that this makes it difficult to attribute token usage to specific projects.

## Installation

Since this package is not yet published to PyPI, you can install it directly from the GitHub repository.

### Method 1: Install directly from GitHub (Recommended)

This is the easiest way to install the tool without manually cloning the repository.

**Using `uv` (Recommended):**

```bash
uv tool install git+https://github.com/ceshine/gemini-cli-usage-analyzer.git
```

**Using `pipx`:**

```bash
pipx install git+https://github.com/ceshine/gemini-cli-usage-analyzer.git
```

**Using `pip`:**

```bash
pip install git+https://github.com/ceshine/gemini-cli-usage-analyzer.git
```

### Method 2: Clone and Install Locally

If you want to modify the code or prefer a local copy:

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/ceshine/gemini-cli-usage-analyzer.git
    cd gemini-cli-usage-analyzer
    ```
2.  **Install:**
    *   Using `uv`: `uv tool install .`
    *   Using `pip`: `pip install .`

After installation, verify it works:
```bash
gemini-cli-usage-analyzer --help
```

## Usage

Run the tool by providing the path to your project directory or a specific log file:

```bash
gemini-cli-usage-analyzer [OPTIONS] LOG_FILE_PATH
```

### Arguments

*   `LOG_FILE_PATH`: The path to the directory containing the logs or a specific log file (`.log` or `.jsonl`).
    *   If a **directory** is provided, the tool automatically searches for `telemetry.log` (to convert) or `telemetry.jsonl` (to analyze) within that directory or its `.gemini` subdirectory.
    *   If a **file** is provided, it processes that specific file.

### Options

*   `-tz`, `--timezone TEXT`: Set the timezone for daily aggregation (e.g., `Asia/Tokyo`, `America/New_York`). Defaults to the system's local time.
*   `--enable-archiving`: If set, moves processed log files to `/tmp` to save space. **Only use this if no Gemini CLI instance is currently running** to avoid locking issues.
*   `--log-simplify-level INTEGER`: Controls how much the logs are simplified to save space (Default: 1).
    *   `0`: No simplification.
    *   `1`: Default simplification.
    *   `2`: Trim fields.
    *   `3`: Trim attributes.

### Examples

**Analyze the current directory (uses default timezone):**

```bash
gemini-cli-usage-analyzer .
```

**Recommended: Use the highest level of simplification and pruning if you just want token usage statistics:**

```bash
gemini-cli-usage-analyzer . --log-simplify-level 3
```

**Analyze with a specific timezone:**

```bash
gemini-cli-usage-analyzer . -tz "Asia/Taipei"
```

**Analyze a specific converted log file:**

```bash
gemini-cli-usage-analyzer .gemini/telemetry.jsonl
```

**Example output**:

```text
Found existing output. Appending new entries after 2025-12-02T14:27:22.499Z...
Successfully converted 193 records to .gemini/telemetry.jsonl (Skipped 210)
Converted .gemini/telemetry.log to .gemini/telemetry.jsonl with archiving DISABLED
Reading .gemini/telemetry.jsonl...

Found 988 inference events.

Daily Token Usage
┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ Date       ┃ Model                 ┃ Requests ┃ Input Tokens ┃ Output Tokens ┃ Cached Tokens ┃ Thoughts Tokens ┃  Cost ($) ┃ Total Tokens ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ 2025-11-30 │ gemini-2.5-flash      │       18 │      322,912 │         8,449 │       192,173 │           6,428 │  0.082179 │      337,789 │
│ 2025-11-30 │ gemini-2.5-flash-lite │       62 │      289,028 │         5,235 │       139,414 │           4,926 │  0.022511 │      299,189 │
│ 2025-11-30 │ gemini-3-pro-preview  │       39 │      639,745 │         7,413 │       375,136 │          26,888 │  1.015857 │      674,046 │
│ 2025-12-01 │ gemini-2.5-flash      │       46 │    2,763,239 │        10,802 │       673,710 │          20,831 │  0.726153 │    2,794,872 │
│ 2025-12-01 │ gemini-2.5-flash-lite │       87 │      323,382 │         9,174 │       205,591 │           6,271 │  0.023097 │      338,827 │
│ 2025-12-01 │ gemini-3-pro-preview  │       97 │    9,302,018 │        21,296 │     7,774,975 │          54,202 │  8.719649 │    9,377,516 │
│ 2025-12-02 │ gemini-2.5-flash      │      101 │    1,964,844 │        29,145 │     1,183,023 │          38,714 │  0.439684 │    2,032,703 │
│ 2025-12-02 │ gemini-2.5-flash-lite │      297 │    1,098,789 │        30,315 │       679,827 │          24,154 │  0.080679 │    1,153,258 │
│ 2025-12-02 │ gemini-2.5-pro        │        5 │       22,361 │         1,351 │         7,562 │           2,055 │  0.053504 │       25,767 │
│ 2025-12-02 │ gemini-3-pro-preview  │      177 │    2,604,693 │        65,039 │     1,718,984 │          94,423 │  4.028759 │    2,764,155 │
│ 2025-12-03 │ gemini-2.5-flash      │        3 │       26,980 │           648 │             0 │           1,027 │  0.012282 │       28,655 │
│ 2025-12-03 │ gemini-2.5-flash-lite │       48 │      189,147 │         2,616 │       128,225 │           1,743 │  0.011041 │      193,506 │
│ 2025-12-03 │ gemini-3-pro-preview  │        8 │       69,279 │         2,000 │        30,576 │           4,274 │  0.158809 │       75,553 │
├────────────┼───────────────────────┼──────────┼──────────────┼───────────────┼───────────────┼─────────────────┼───────────┼──────────────┤
│            │ Grand Total           │      988 │   19,616,417 │       193,483 │    13,109,196 │         285,936 │ 15.374205 │   20,095,836 │
└────────────┴───────────────────────┴──────────┴──────────────┴───────────────┴───────────────┴─────────────────┴───────────┴──────────────┘


Daily Aggregated Costs
┏━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃ Date       ┃  Cost ($) ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 2025-11-30 │  1.120548 │
│ 2025-12-01 │  9.468898 │
│ 2025-12-02 │  4.602627 │
│ 2025-12-03 │  0.182132 │
├────────────┼───────────┤
│            │ 15.374205 │
└────────────┴───────────┘


Overall Token Usage by Model
┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ Model                 ┃ Requests ┃ Input Tokens ┃ Output Tokens ┃ Cached Tokens ┃ Thoughts Tokens ┃  Cost ($) ┃ Total Tokens ┃
┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ gemini-2.5-flash      │      168 │    5,077,975 │        49,044 │     2,048,906 │          67,000 │  1.260298 │    5,194,019 │
│ gemini-2.5-flash-lite │      494 │    1,900,346 │        47,340 │     1,153,057 │          37,094 │  0.137329 │    1,984,780 │
│ gemini-2.5-pro        │        5 │       22,361 │         1,351 │         7,562 │           2,055 │  0.053504 │       25,767 │
│ gemini-3-pro-preview  │      321 │   12,615,735 │        95,748 │     9,899,671 │         179,787 │ 13.923074 │   12,891,270 │
├───────────────────────┼──────────┼──────────────┼───────────────┼───────────────┼─────────────────┼───────────┼──────────────┤
│ Grand Total           │      988 │   19,616,417 │       193,483 │    13,109,196 │         285,936 │ 15.374205 │   20,095,836 │
└───────────────────────┴──────────┴──────────────┴───────────────┴───────────────┴─────────────────┴───────────┴──────────────┘
```

## Managing Disk Space

To prevent OpenTelemetry log files from consuming excessive disk space, especially if you enable a low `log-simplify-level`, it is recommended to periodically process and archive them.

The `--enable-archiving` option moves processed log files to `/tmp` to save space. **Note that files in `/tmp` are typically deleted automatically upon the next system reboot.** This behavior effectively acts as a "trash" mechanism, allowing you to recover the file before a reboot if needed, but ensuring it doesn't permanently occupy disk space.

**⚠️ IMPORTANT WARNING:** Only use `--enable-archiving` if no Gemini CLI instances are currently running and actively writing to the log file. Running with archiving enabled while Gemini CLI is active can lead to file locking issues, data corruption, or data loss.

**Example:**

```bash
gemini-cli-usage-analyzer . --enable-archiving
```

## Internal Workflows

Understanding how `gemini-cli-usage-analyzer` processes your data can help you troubleshoot issues and optimize your usage.

### 1. Log Conversion and Simplification

The Gemini CLI generates OpenTelemetry logs as a series of concatenated, indented JSON objects (not a valid single JSON array or standard JSON Lines file). This tool handles this specific format by:

*   **Heuristic Parsing:** It reads the raw log file line-by-line, accumulating lines until it detects a closing brace `}` that signifies the end of a JSON object. This allows it to parse the stream of objects efficiently without loading the entire file into memory.
*   **Incremental Processing:** It checks the last timestamp in the target `.jsonl` file to process only new entries, ensuring efficiency.
*   **Simplification:** Based on the `--log-simplify-level` (default: 1), it filters out unnecessary events and fields. Level 1 keeps only API requests and responses, while Level 3 retains only the essential token usage metrics, significantly reducing file size.
*   **Archiving:** If `--enable-archiving` is set, the original raw log file is moved to `/tmp` (or a configured folder) after successful processing. This prevents the raw logs from growing indefinitely.

### 2. Pricing Data Collection

To provide accurate cost estimates, the tool fetches the latest model pricing and context window information from the [LiteLLM repository](https://github.com/BerriAI/litellm).

*   **Source:** `https://raw.githubusercontent.com/BerriAI/litellm/refs/heads/main/model_prices_and_context_window.json`
*   **Caching:** The pricing data is cached locally (default: `~/.gemini/prices.json`) for 24 hours to reduce network requests and improve performance. An active internet connection is required to update this cache. You can override the cache location by setting the `PRICE_CACHE_PATH` environment variable.

## Roadmap (To-dos)

* Export the log simplification and pruning tool to allow users to manually clean up the JSONL log file.
* Support processing multiple projects at the same time.
* Support using [Send2Trash](https://github.com/arsenetar/send2trash) for a cross-platform native file trashing experience instead of moving to `/tmp`.

## Acknowledgements

- The [AGENTS.md](./AGENTS.md) was adapted from the examples in this blog post: [Getting Good Results from Claude Code](https://www.dzombak.com/blog/2025/08/getting-good-results-from-claude-code/).
